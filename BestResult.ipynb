{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "NOk99_8liroG",
    "outputId": "095c21f5-a667-44f2-d78d-bc0f4174d457"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "lz4 not available, disabling compression. To install lz4, run `pip install lz4`.\n",
      "wandb not available, to install wandb, run `pip install wandb`.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from catalyst.dl import SupervisedRunner\n",
    "from catalyst.dl.callbacks import AUCCallback, F1ScoreCallback\n",
    "from catalyst.contrib.schedulers import OneCycleLR\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import copy\n",
    "from random import shuffle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c3Vcy7txiroO"
   },
   "outputs": [],
   "source": [
    "r = re.compile(r'[\\a-z]+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iNI3r6IFiroV"
   },
   "outputs": [],
   "source": [
    "# В google colab стоит pytorch версии 1.1.0, в котором ещё не были добалены трансформеры\n",
    "# Поэтому используется чужой код. Ссылка в отчете\n",
    "\n",
    "class PositionalEncoder(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_len = 200):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, d_model, 2):\n",
    "                pe[pos, i] = np.sin(pos / (10000 ** ((2 * i) / d_model)))\n",
    "                pe[pos, i + 1] = np.cos(pos / (10000 ** ((2 * (i + 1)) / d_model)))\n",
    "                \n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x * np.sqrt(self.d_model)\n",
    "        seq_len = x.size(1)\n",
    "        x = x + torch.autograd.Variable(self.pe[:,:seq_len], requires_grad=False).cuda()\n",
    "        return x\n",
    "\n",
    "    \n",
    "def attention(q, k, v, d_model, dropout=None):\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) /  np.sqrt(d_model) \n",
    "        scores = F.softmax(scores, dim=-1)\n",
    "        scores = dropout(scores)\n",
    "        \n",
    "        output = torch.matmul(scores, v)\n",
    "        return output\n",
    "\n",
    "    \n",
    "# Изменен алгоритм подсчета score на dot\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, d_model, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, q, k, v):\n",
    "        bs = q.size(0)\n",
    "\n",
    "        k = k.view(bs, -1, self.d_model).transpose(1,2)\n",
    "        q = q.view(bs, -1, self.d_model).transpose(1,2)\n",
    "        v = v.view(bs, -1, self.d_model).transpose(1,2)\n",
    "        scores = attention(q, k, v, self.d_model, self.dropout)\n",
    "        \n",
    "        output = scores.transpose(1,2).contiguous().view(bs, -1, self.d_model)\n",
    "    \n",
    "        return output\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, dropout = 0.1):\n",
    "        super().__init__() \n",
    "        self.linear_1 = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(d_model, d_model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.dropout(F.relu(self.linear_1(x)))\n",
    "        x = self.linear_2(x)\n",
    "        return x\n",
    "    \n",
    "class Norm(nn.Module):\n",
    "    def __init__(self, d_model, eps = 1e-6):\n",
    "        super().__init__()\n",
    "        self.size = d_model\n",
    "        self.alpha = nn.Parameter(torch.ones(self.size))\n",
    "        self.bias = nn.Parameter(torch.zeros(self.size))\n",
    "        self.eps = eps\n",
    "    def forward(self, x):\n",
    "        norm = self.alpha * (x - x.mean(dim=-1, keepdim=True)) / (x.std(dim=-1, keepdim=True) + self.eps) + self.bias\n",
    "        return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-QdWFNZnrmH8"
   },
   "outputs": [],
   "source": [
    "# Чтение параметров для embeddings.\n",
    "def get_coefs(word,*arr): \n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "embeddings_index = dict(get_coefs(*o.strip().split()) for o in open('glove.6B.50d.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mBBSQ99Xiroi"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "X = [' '.join(r.findall(i.lower())) for i in train['comment_text'].values]\n",
    "y = train[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values.tolist()\n",
    "\n",
    "# Для ускорения работы сокращаем длину до 200 токен\n",
    "new_X = []\n",
    "new_y = []\n",
    "for x, y_i in zip(X, y):\n",
    "    if len(x) > 200:\n",
    "        for i in range(0, len(x), 200):\n",
    "            new_X.append(x[i:min(200+i, len(x))])\n",
    "            new_y.append(y_i)\n",
    "    else:\n",
    "        new_X.append(x)\n",
    "        new_y.append(y_i)\n",
    "\n",
    "Xy = list(zip(X, y))\n",
    "shuffle(Xy)\n",
    "X, y = [i[0] for i in Xy], [i[1] for i in Xy]\n",
    "\n",
    "\n",
    "# Готовим embedding\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "X = tokenizer.texts_to_sequences(X)\n",
    "X = pad_sequences(X, maxlen=200)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = len(word_index)\n",
    "embedding_matrix = np.zeros((nb_words + 1, 50))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: \n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6GGrlYlvirob"
   },
   "outputs": [],
   "source": [
    "def get_clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n",
    "\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, d_model, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.norm_1 = Norm(d_model)\n",
    "        self.norm_2 = Norm(d_model)\n",
    "        self.attn = Attention(d_model)\n",
    "        self.ff = FeedForward(d_model)\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x2 = self.norm_1(x)\n",
    "        x = x + self.dropout_1(self.attn(x2,x2,x2))\n",
    "        x2 = self.norm_2(x)\n",
    "        x = x + self.dropout_2(self.ff(x2))\n",
    "        return x\n",
    "\n",
    "\n",
    "class AttentionModel(nn.Module):\n",
    "    def __init__(self, N, vocab_size=nb_words, d_model=50, output_shape=6):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.N = N\n",
    "        self.embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.embed.weight = nn.Parameter(torch.FloatTensor(embedding_matrix))\n",
    "        self.pe = PositionalEncoder(d_model)\n",
    "        self.layers = get_clones(AttentionLayer(d_model), N)\n",
    "        self.norm = Norm(d_model)\n",
    "        self.output_shape = output_shape\n",
    "        self.output = nn.Linear(d_model, output_shape)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, src):\n",
    "        x = self.embed(src)\n",
    "        x = self.pe(x)\n",
    "        for i in range(self.N):\n",
    "            x = self.layers[i](x)\n",
    "        x = torch.sum(self.norm(x), dim=1)\n",
    "        x = x.view(-1, self.d_model)\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "PHlxMu0tirop",
    "outputId": "3a47d992-1f5b-4851-c1bb-b0704866adb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/20 * Epoch (train): 100% 1995/1995 [02:00<00:00, 16.57it/s, _timers/_fps=4946.842, f1_score=0.177, loss=14.122]\n",
      "0/20 * Epoch (valid): 100% 499/499 [00:09<00:00, 55.30it/s, _timers/_fps=7006.015, f1_score=5.406e-05, loss=16.073]\n",
      "[2019-09-27 23:28:12,424] \n",
      "0/20 * Epoch 0 (train): _base/lr=0.0010 | _base/momentum=0.8750 | _timers/_fps=5637.6076 | _timers/batch_time=0.0115 | _timers/data_time=0.0015 | _timers/model_time=0.0100 | auc/_mean=0.5526 | auc/class_0=0.5526 | f1_score=0.0663 | loss=28.2563\n",
      "0/20 * Epoch 0 (valid): _base/lr=0.0010 | _base/momentum=0.8437 | _timers/_fps=6928.5570 | _timers/batch_time=0.0094 | _timers/data_time=0.0012 | _timers/model_time=0.0082 | auc/_mean=0.8760 | auc/class_0=0.8760 | f1_score=0.1014 | loss=24.5353\n",
      "1/20 * Epoch (train): 100% 1995/1995 [01:59<00:00, 16.65it/s, _timers/_fps=5213.453, f1_score=0.375, loss=18.597]\n",
      "1/20 * Epoch (valid): 100% 499/499 [00:09<00:00, 55.44it/s, _timers/_fps=3962.790, f1_score=0.091, loss=13.641]\n",
      "[2019-09-27 23:30:22,465] \n",
      "1/20 * Epoch 1 (train): _base/lr=0.0010 | _base/momentum=0.8250 | _timers/_fps=5637.9869 | _timers/batch_time=0.0115 | _timers/data_time=0.0015 | _timers/model_time=0.0100 | auc/_mean=0.8380 | auc/class_0=0.8380 | f1_score=0.2454 | loss=22.2015\n",
      "1/20 * Epoch 1 (valid): _base/lr=0.0010 | _base/momentum=0.8013 | _timers/_fps=7128.4657 | _timers/batch_time=0.0091 | _timers/data_time=0.0011 | _timers/model_time=0.0079 | auc/_mean=0.9308 | auc/class_0=0.9308 | f1_score=0.2484 | loss=20.5988\n",
      "2/20 * Epoch (train): 100% 1995/1995 [01:59<00:00, 16.65it/s, _timers/_fps=4661.957, f1_score=0.567, loss=15.918]\n",
      "2/20 * Epoch (valid): 100% 499/499 [00:09<00:00, 54.67it/s, _timers/_fps=4410.777, f1_score=0.227, loss=45.411]\n",
      "[2019-09-27 23:32:32,600] \n",
      "2/20 * Epoch 2 (train): _base/lr=0.0010 | _base/momentum=0.8053 | _timers/_fps=5502.4892 | _timers/batch_time=0.0118 | _timers/data_time=0.0015 | _timers/model_time=0.0102 | auc/_mean=0.8880 | auc/class_0=0.8880 | f1_score=0.2949 | loss=21.6256\n",
      "2/20 * Epoch 2 (valid): _base/lr=0.0009 | _base/momentum=0.8119 | _timers/_fps=6661.9239 | _timers/batch_time=0.0097 | _timers/data_time=0.0012 | _timers/model_time=0.0085 | auc/_mean=0.9351 | auc/class_0=0.9351 | f1_score=0.2800 | loss=20.5631\n",
      "3/20 * Epoch (train): 100% 1995/1995 [02:00<00:00, 16.62it/s, _timers/_fps=4402.963, f1_score=0.157, loss=34.647]\n",
      "3/20 * Epoch (valid): 100% 499/499 [00:09<00:00, 54.10it/s, _timers/_fps=6078.151, f1_score=0.463, loss=73.823]\n",
      "[2019-09-27 23:34:42,503] \n",
      "3/20 * Epoch 3 (train): _base/lr=0.0009 | _base/momentum=0.8158 | _timers/_fps=5430.4697 | _timers/batch_time=0.0119 | _timers/data_time=0.0015 | _timers/model_time=0.0103 | auc/_mean=0.9280 | auc/class_0=0.9280 | f1_score=0.3510 | loss=21.4625\n",
      "3/20 * Epoch 3 (valid): _base/lr=0.0009 | _base/momentum=0.8224 | _timers/_fps=6684.9860 | _timers/batch_time=0.0097 | _timers/data_time=0.0012 | _timers/model_time=0.0084 | auc/_mean=0.9417 | auc/class_0=0.9417 | f1_score=0.3981 | loss=20.7420\n",
      "4/20 * Epoch (train): 100% 1995/1995 [02:00<00:00, 16.58it/s, _timers/_fps=4307.580, f1_score=0.795, loss=0.267]\n",
      "4/20 * Epoch (valid): 100% 499/499 [00:09<00:00, 55.16it/s, _timers/_fps=6606.991, f1_score=0.657, loss=1.014]\n",
      "[2019-09-27 23:36:53,135] \n",
      "4/20 * Epoch 4 (train): _base/lr=0.0009 | _base/momentum=0.8264 | _timers/_fps=5439.0157 | _timers/batch_time=0.0119 | _timers/data_time=0.0015 | _timers/model_time=0.0104 | auc/_mean=0.9350 | auc/class_0=0.9350 | f1_score=0.5087 | loss=16.5668\n",
      "4/20 * Epoch 4 (valid): _base/lr=0.0008 | _base/momentum=0.8330 | _timers/_fps=6778.1858 | _timers/batch_time=0.0096 | _timers/data_time=0.0012 | _timers/model_time=0.0083 | auc/_mean=0.9534 | auc/class_0=0.9534 | f1_score=0.5935 | loss=13.0654\n",
      "5/20 * Epoch (train): 100% 1995/1995 [02:00<00:00, 16.58it/s, _timers/_fps=4993.498, f1_score=0.445, loss=0.288]\n",
      "5/20 * Epoch (valid): 100% 499/499 [00:09<00:00, 55.44it/s, _timers/_fps=6678.496, f1_score=0.540, loss=10.919]\n",
      "[2019-09-27 23:39:04,289] \n",
      "5/20 * Epoch 5 (train): _base/lr=0.0008 | _base/momentum=0.8369 | _timers/_fps=5586.4179 | _timers/batch_time=0.0116 | _timers/data_time=0.0015 | _timers/model_time=0.0101 | auc/_mean=0.9637 | auc/class_0=0.9637 | f1_score=0.6126 | loss=13.6466\n",
      "5/20 * Epoch 5 (valid): _base/lr=0.0008 | _base/momentum=0.8435 | _timers/_fps=6858.7448 | _timers/batch_time=0.0094 | _timers/data_time=0.0011 | _timers/model_time=0.0083 | auc/_mean=0.9598 | auc/class_0=0.9598 | f1_score=0.5870 | loss=12.9590\n",
      "6/20 * Epoch (train): 100% 1995/1995 [02:00<00:00, 16.57it/s, _timers/_fps=4800.434, f1_score=0.446, loss=0.641]\n",
      "6/20 * Epoch (valid): 100% 499/499 [00:09<00:00, 55.40it/s, _timers/_fps=6507.211, f1_score=0.551, loss=10.727]\n",
      "[2019-09-27 23:41:14,490] \n",
      "6/20 * Epoch 6 (train): _base/lr=0.0008 | _base/momentum=0.8475 | _timers/_fps=5651.1638 | _timers/batch_time=0.0115 | _timers/data_time=0.0014 | _timers/model_time=0.0100 | auc/_mean=0.9696 | auc/class_0=0.9696 | f1_score=0.6423 | loss=14.6040\n",
      "6/20 * Epoch 6 (valid): _base/lr=0.0007 | _base/momentum=0.8541 | _timers/_fps=7028.3439 | _timers/batch_time=0.0092 | _timers/data_time=0.0011 | _timers/model_time=0.0081 | auc/_mean=0.9625 | auc/class_0=0.9625 | f1_score=0.6220 | loss=15.4336\n",
      "7/20 * Epoch (train): 100% 1995/1995 [02:00<00:00, 16.58it/s, _timers/_fps=4787.421, f1_score=0.276, loss=0.409]\n",
      "7/20 * Epoch (valid): 100% 499/499 [00:09<00:00, 55.20it/s, _timers/_fps=5799.120, f1_score=0.258, loss=12.698]\n",
      "[2019-09-27 23:43:24,513] \n",
      "7/20 * Epoch 7 (train): _base/lr=0.0007 | _base/momentum=0.8581 | _timers/_fps=5650.5722 | _timers/batch_time=0.0115 | _timers/data_time=0.0014 | _timers/model_time=0.0100 | auc/_mean=0.9793 | auc/class_0=0.9793 | f1_score=0.6774 | loss=17.4226\n",
      "7/20 * Epoch 7 (valid): _base/lr=0.0007 | _base/momentum=0.8647 | _timers/_fps=7005.6783 | _timers/batch_time=0.0092 | _timers/data_time=0.0012 | _timers/model_time=0.0080 | auc/_mean=0.9600 | auc/class_0=0.9600 | f1_score=0.5304 | loss=13.2150\n",
      "8/20 * Epoch (train): 100% 1995/1995 [02:00<00:00, 16.59it/s, _timers/_fps=5047.582, f1_score=0.715, loss=63.151]\n",
      "8/20 * Epoch (valid): 100% 499/499 [00:08<00:00, 55.66it/s, _timers/_fps=6837.726, f1_score=0.545, loss=12.359]\n",
      "[2019-09-27 23:45:35,064] \n",
      "8/20 * Epoch 8 (train): _base/lr=0.0007 | _base/momentum=0.8686 | _timers/_fps=5663.1152 | _timers/batch_time=0.0114 | _timers/data_time=0.0014 | _timers/model_time=0.0100 | auc/_mean=0.9806 | auc/class_0=0.9806 | f1_score=0.6809 | loss=12.1772\n",
      "8/20 * Epoch 8 (valid): _base/lr=0.0006 | _base/momentum=0.8752 | _timers/_fps=6810.8738 | _timers/batch_time=0.0095 | _timers/data_time=0.0010 | _timers/model_time=0.0085 | auc/_mean=0.9594 | auc/class_0=0.9594 | f1_score=0.5903 | loss=9.7129\n",
      "9/20 * Epoch (train): 100% 1995/1995 [02:00<00:00, 16.58it/s, _timers/_fps=4358.638, f1_score=0.634, loss=1.229]\n",
      "9/20 * Epoch (valid): 100% 499/499 [00:09<00:00, 55.20it/s, _timers/_fps=5216.289, f1_score=0.517, loss=0.317]\n",
      "[2019-09-27 23:47:45,742] \n",
      "9/20 * Epoch 9 (train): _base/lr=0.0006 | _base/momentum=0.8792 | _timers/_fps=5526.9096 | _timers/batch_time=0.0117 | _timers/data_time=0.0015 | _timers/model_time=0.0102 | auc/_mean=0.9857 | auc/class_0=0.9857 | f1_score=0.6919 | loss=9.8928\n",
      "9/20 * Epoch 9 (valid): _base/lr=0.0006 | _base/momentum=0.8858 | _timers/_fps=6721.8699 | _timers/batch_time=0.0096 | _timers/data_time=0.0011 | _timers/model_time=0.0085 | auc/_mean=0.9583 | auc/class_0=0.9583 | f1_score=0.5972 | loss=9.4574\n",
      "10/20 * Epoch (train): 100% 1995/1995 [02:00<00:00, 16.57it/s, _timers/_fps=5615.452, f1_score=0.794, loss=12.810]\n",
      "10/20 * Epoch (valid): 100% 499/499 [00:09<00:00, 55.41it/s, _timers/_fps=5937.524, f1_score=0.557, loss=25.834]\n",
      "[2019-09-27 23:49:56,324] \n",
      "10/20 * Epoch 10 (train): _base/lr=0.0006 | _base/momentum=0.8897 | _timers/_fps=5607.9462 | _timers/batch_time=0.0115 | _timers/data_time=0.0015 | _timers/model_time=0.0100 | auc/_mean=0.9884 | auc/class_0=0.9884 | f1_score=0.7108 | loss=9.5366\n",
      "10/20 * Epoch 10 (valid): _base/lr=0.0005 | _base/momentum=0.8963 | _timers/_fps=6821.4767 | _timers/batch_time=0.0095 | _timers/data_time=0.0011 | _timers/model_time=0.0083 | auc/_mean=0.9546 | auc/class_0=0.9546 | f1_score=0.5848 | loss=9.4330\n",
      "11/20 * Epoch (train): 100% 1995/1995 [02:00<00:00, 16.59it/s, _timers/_fps=4419.782, f1_score=0.840, loss=0.514]\n",
      "11/20 * Epoch (valid): 100% 499/499 [00:09<00:00, 55.00it/s, _timers/_fps=5805.140, f1_score=0.628, loss=13.950]\n",
      "[2019-09-27 23:52:06,406] \n",
      "11/20 * Epoch 11 (train): _base/lr=0.0005 | _base/momentum=0.9003 | _timers/_fps=5612.2969 | _timers/batch_time=0.0116 | _timers/data_time=0.0015 | _timers/model_time=0.0100 | auc/_mean=0.9886 | auc/class_0=0.9886 | f1_score=0.7140 | loss=11.2887\n",
      "11/20 * Epoch 11 (valid): _base/lr=0.0005 | _base/momentum=0.9069 | _timers/_fps=6955.8917 | _timers/batch_time=0.0093 | _timers/data_time=0.0012 | _timers/model_time=0.0081 | auc/_mean=0.9572 | auc/class_0=0.9572 | f1_score=0.5873 | loss=15.8105\n",
      "12/20 * Epoch (train): 100% 1995/1995 [02:00<00:00, 16.60it/s, _timers/_fps=4841.822, f1_score=0.550, loss=0.638]\n",
      "12/20 * Epoch (valid): 100% 499/499 [00:08<00:00, 55.72it/s, _timers/_fps=6457.277, f1_score=0.673, loss=1.031]\n",
      "[2019-09-27 23:54:16,299] \n",
      "12/20 * Epoch 12 (train): _base/lr=0.0005 | _base/momentum=0.9108 | _timers/_fps=5690.6661 | _timers/batch_time=0.0114 | _timers/data_time=0.0014 | _timers/model_time=0.0099 | auc/_mean=0.9909 | auc/class_0=0.9909 | f1_score=0.7319 | loss=16.0628\n",
      "12/20 * Epoch 12 (valid): _base/lr=0.0004 | _base/momentum=0.9174 | _timers/_fps=6677.0178 | _timers/batch_time=0.0097 | _timers/data_time=0.0011 | _timers/model_time=0.0086 | auc/_mean=0.9555 | auc/class_0=0.9555 | f1_score=0.6237 | loss=16.2176\n",
      "13/20 * Epoch (train): 100% 1995/1995 [02:00<00:00, 16.60it/s, _timers/_fps=4949.214, f1_score=0.794, loss=121.687]\n",
      "13/20 * Epoch (valid): 100% 499/499 [00:09<00:00, 55.03it/s, _timers/_fps=6998.708, f1_score=0.704, loss=12.117]\n",
      "[2019-09-27 23:56:26,263] \n",
      "13/20 * Epoch 13 (train): _base/lr=0.0004 | _base/momentum=0.9214 | _timers/_fps=5663.6000 | _timers/batch_time=0.0114 | _timers/data_time=0.0015 | _timers/model_time=0.0099 | auc/_mean=0.9918 | auc/class_0=0.9918 | f1_score=0.7444 | loss=15.3358\n",
      "13/20 * Epoch 13 (valid): _base/lr=0.0004 | _base/momentum=0.9280 | _timers/_fps=6954.6592 | _timers/batch_time=0.0093 | _timers/data_time=0.0011 | _timers/model_time=0.0082 | auc/_mean=0.9555 | auc/class_0=0.9555 | f1_score=0.6154 | loss=16.2775\n",
      "14/20 * Epoch (train): 100% 1995/1995 [02:00<00:00, 16.62it/s, _timers/_fps=4706.339, f1_score=0.920, loss=0.212]\n",
      "14/20 * Epoch (valid): 100% 499/499 [00:09<00:00, 55.38it/s, _timers/_fps=6524.767, f1_score=0.513, loss=35.270]\n",
      "[2019-09-27 23:58:36,540] \n",
      "14/20 * Epoch 14 (train): _base/lr=0.0004 | _base/momentum=0.9320 | _timers/_fps=5718.1656 | _timers/batch_time=0.0113 | _timers/data_time=0.0014 | _timers/model_time=0.0099 | auc/_mean=0.9927 | auc/class_0=0.9927 | f1_score=0.7576 | loss=14.5967\n",
      "14/20 * Epoch 14 (valid): _base/lr=0.0003 | _base/momentum=0.9385 | _timers/_fps=6992.7557 | _timers/batch_time=0.0092 | _timers/data_time=0.0011 | _timers/model_time=0.0081 | auc/_mean=0.9540 | auc/class_0=0.9540 | f1_score=0.5876 | loss=9.4196\n",
      "15/20 * Epoch (train): 100% 1995/1995 [01:59<00:00, 16.67it/s, _timers/_fps=5204.356, f1_score=0.778, loss=12.211]\n",
      "15/20 * Epoch (valid): 100% 499/499 [00:08<00:00, 55.82it/s, _timers/_fps=6947.087, f1_score=0.585, loss=11.409]\n",
      "[2019-09-28 00:00:46,797] \n",
      "15/20 * Epoch 15 (train): _base/lr=0.0003 | _base/momentum=0.9425 | _timers/_fps=5827.1206 | _timers/batch_time=0.0111 | _timers/data_time=0.0014 | _timers/model_time=0.0097 | auc/_mean=0.9935 | auc/class_0=0.9935 | f1_score=0.7663 | loss=9.0107\n",
      "15/20 * Epoch 15 (valid): _base/lr=0.0003 | _base/momentum=0.9491 | _timers/_fps=7195.4032 | _timers/batch_time=0.0090 | _timers/data_time=0.0011 | _timers/model_time=0.0078 | auc/_mean=0.9526 | auc/class_0=0.9526 | f1_score=0.6105 | loss=9.2522\n",
      "16/20 * Epoch (train): 100% 1995/1995 [01:59<00:00, 16.68it/s, _timers/_fps=4940.742, f1_score=0.922, loss=0.253]\n",
      "16/20 * Epoch (valid): 100% 499/499 [00:09<00:00, 54.97it/s, _timers/_fps=6818.101, f1_score=0.584, loss=0.764]\n",
      "[2019-09-28 00:02:56,192] \n",
      "16/20 * Epoch 16 (train): _base/lr=0.0003 | _base/momentum=0.9531 | _timers/_fps=5894.5101 | _timers/batch_time=0.0110 | _timers/data_time=0.0014 | _timers/model_time=0.0096 | auc/_mean=0.9941 | auc/class_0=0.9941 | f1_score=0.7759 | loss=8.9764\n",
      "16/20 * Epoch 16 (valid): _base/lr=0.0002 | _base/momentum=0.9597 | _timers/_fps=6940.1983 | _timers/batch_time=0.0094 | _timers/data_time=0.0012 | _timers/model_time=0.0082 | auc/_mean=0.9517 | auc/class_0=0.9517 | f1_score=0.5683 | loss=9.6266\n",
      "17/20 * Epoch (train): 100% 1995/1995 [01:59<00:00, 16.63it/s, _timers/_fps=4737.403, f1_score=0.830, loss=12.578]\n",
      "17/20 * Epoch (valid): 100% 499/499 [00:08<00:00, 55.69it/s, _timers/_fps=6918.261, f1_score=0.405, loss=13.074]\n",
      "[2019-09-28 00:05:05,700] \n",
      "17/20 * Epoch 17 (train): _base/lr=0.0002 | _base/momentum=0.9636 | _timers/_fps=5836.2655 | _timers/batch_time=0.0111 | _timers/data_time=0.0014 | _timers/model_time=0.0097 | auc/_mean=0.9943 | auc/class_0=0.9943 | f1_score=0.7801 | loss=10.8064\n",
      "17/20 * Epoch 17 (valid): _base/lr=0.0002 | _base/momentum=0.9702 | _timers/_fps=7082.6941 | _timers/batch_time=0.0091 | _timers/data_time=0.0011 | _timers/model_time=0.0079 | auc/_mean=0.9490 | auc/class_0=0.9490 | f1_score=0.6212 | loss=14.7995\n",
      "18/20 * Epoch (train): 100% 1995/1995 [01:59<00:00, 16.64it/s, _timers/_fps=5231.640, f1_score=0.871, loss=11.954]\n",
      "18/20 * Epoch (valid): 100% 499/499 [00:08<00:00, 55.81it/s, _timers/_fps=5825.549, f1_score=1.102e-07, loss=0.049]\n",
      "[2019-09-28 00:07:15,194] \n",
      "18/20 * Epoch 18 (train): _base/lr=0.0002 | _base/momentum=0.9742 | _timers/_fps=5792.4341 | _timers/batch_time=0.0112 | _timers/data_time=0.0014 | _timers/model_time=0.0097 | auc/_mean=0.9952 | auc/class_0=0.9952 | f1_score=0.7909 | loss=15.1139\n",
      "18/20 * Epoch 18 (valid): _base/lr=0.0001 | _base/momentum=0.9808 | _timers/_fps=6891.8506 | _timers/batch_time=0.0094 | _timers/data_time=0.0011 | _timers/model_time=0.0083 | auc/_mean=0.9483 | auc/class_0=0.9483 | f1_score=0.6297 | loss=16.5540\n",
      "19/20 * Epoch (train): 100% 1995/1995 [02:00<00:00, 16.62it/s, _timers/_fps=4566.627, f1_score=0.777, loss=12.802]\n",
      "19/20 * Epoch (valid): 100% 499/499 [00:08<00:00, 55.50it/s, _timers/_fps=6432.673, f1_score=0.785, loss=1.274]\n",
      "[2019-09-28 00:09:24,870] \n",
      "19/20 * Epoch 19 (train): _base/lr=0.0001 | _base/momentum=0.9847 | _timers/_fps=5753.2560 | _timers/batch_time=0.0113 | _timers/data_time=0.0014 | _timers/model_time=0.0098 | auc/_mean=0.9954 | auc/class_0=0.9954 | f1_score=0.7940 | loss=15.9827\n",
      "19/20 * Epoch 19 (valid): _base/lr=0.0001 | _base/momentum=0.9990 | _timers/_fps=6878.7539 | _timers/batch_time=0.0094 | _timers/data_time=0.0011 | _timers/model_time=0.0083 | auc/_mean=0.9472 | auc/class_0=0.9472 | f1_score=0.6346 | loss=16.6535\n",
      "Top best models:\n",
      "logs/checkpoints//train.15.pth\t9.2522\n"
     ]
    }
   ],
   "source": [
    "runner = SupervisedRunner()\n",
    "\n",
    "\n",
    "weights = 143346 / np.array([15294, 1595, 8449, 478, 7877, 1405])\n",
    "weights = torch.FloatTensor(weights).cuda()\n",
    "\n",
    "X = [torch.LongTensor(i) for i in X]\n",
    "y = [torch.FloatTensor(i) for i in y]\n",
    "X_train, X_test = X[:-len(X)//5], X[-len(X)//5:]\n",
    "y_train, y_test = y[:-len(X)//5], y[-len(X)//5:]\n",
    "\n",
    "loader_train = list(zip(X_train, y_train))\n",
    "loader_test = list(zip(X_test, y_test))\n",
    "\n",
    "\n",
    "loader_train = DataLoader(loader_train, batch_size=2**6, shuffle=True)\n",
    "loader_test = DataLoader(loader_test, batch_size=2**6, shuffle=True)\n",
    "\n",
    "model = AttentionModel(6)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = OneCycleLR(optimizer,\n",
    "    num_steps=20, \n",
    "    lr_range=(0.001, 0.0001),\n",
    "    warmup_steps=2)\n",
    "\n",
    "runner.train(model=model, criterion=nn.BCELoss(reduction='mean', weight=weights),\n",
    "             optimizer=optimizer, scheduler=scheduler,\n",
    "             loaders={'train': loader_train, 'valid': loader_test}, \n",
    "             num_epochs=20, verbose=True, logdir='logs', \n",
    "             callbacks=[F1ScoreCallback(activation='none'), AUCCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "UD0ajOLUirou",
    "outputId": "31a8fc91-c8be-4be0-8d2a-2cacac969d41"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9996606"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "zU_Z2kB6iroy",
    "outputId": "d64ca089-6814-4048-fec5-1b18d07f2fb9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31915/31915 [03:40<00:00, 144.93it/s]\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "\n",
    "model.eval()\n",
    "model.cuda()\n",
    "with torch.no_grad():\n",
    "    for x in tqdm(X[-len(X)//5:]):\n",
    "        x = x.cuda()\n",
    "        y_pred.append((model(x.view(1, -1))).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "d6vsvW5RpydU",
    "outputId": "2117656e-735b-498c-fe53-57fe403c5502"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6872252870144789"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score((np.array([i.numpy() for i in y_test]) > 0) * 1, (np.round(np.array(y_pred).reshape(-1, 6))), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "8L2ni8_kNxYD",
    "outputId": "a6d224c6-6d39-49c4-ed30-fe3bb692482e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8061638446639087"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score((np.array([i.numpy() for i in y_test]) > 0) * 1, (np.round(np.array(y_pred).reshape(-1, 6))), average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "colab_type": "code",
    "id": "itZGWTvxVldk",
    "outputId": "0264b1ae-3b81-4013-ee8e-79178d10b5ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.81      0.69      0.75      2965\n",
      " severe_toxic       0.48      0.29      0.36       300\n",
      "      obscene       0.83      0.69      0.75      1592\n",
      "       threat       0.00      0.00      0.00        89\n",
      "       insult       0.74      0.62      0.67      1515\n",
      "identity_hate       0.00      0.00      0.00       270\n",
      "\n",
      "    micro avg       0.79      0.62      0.69      6731\n",
      "    macro avg       0.48      0.38      0.42      6731\n",
      " weighted avg       0.74      0.62      0.67      6731\n",
      "  samples avg       0.06      0.05      0.05      6731\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning:\n",
      "\n",
      "Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report((np.array([i.numpy() for i in y_test]) > 0) * 1, (np.round(np.array(y_pred).reshape(-1, 6))), \n",
    "                           target_names=['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dqkmj_5S9iUD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "BestResult.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
